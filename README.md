# ğŸ“Š Database Analyzer

## ğŸ“‹ Table des matiÃ¨res

1. [Introduction](#-introduction)
2. [Auteurs](#-auteurs)
3. [Objectifs](#-objectifs-du-projet)
4. [Installation](#-installation)
   - [PrÃ©requis systÃ¨me](#prÃ©requis-systÃ¨me)
   - [Installation du projet](#installation-du-projet)
   - [Installation des donnÃ©es](#installation-des-donnÃ©es)
   - [Lancement de l'analyse](#lancement-de-lanalyse)
5. [Structure du projet](#-structure-du-projet)
6. [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
   - [Configuration automatique](#configuration-automatique)
   - [Analyse des performances](#analyse-des-performances)
   - [Visualisation](#visualisation)
7. [RÃ©sultats](#-rÃ©sultats)
8. [Explication des diffÃ©rences de performance ](#-explication-des-diffÃ©rences-de-performance)
9. [Licence](#-licence)

## ğŸ“ Introduction

Ce projet d'analyse comparative de bases de donnÃ©es a Ã©tÃ© dÃ©veloppÃ© dans le cadre de l'UE "Bases de DonnÃ©es" du Master IngÃ©nierie Logicielle Ã  l'UniversitÃ© de Rennes. Il permet d'Ã©valuer et de comparer les performances de PostgreSQL et MonetDB sur diffÃ©rents types de requÃªtes et scÃ©narios d'utilisation.

L'outil propose une suite complÃ¨te de tests automatisÃ©s, gÃ©nÃ©rant des visualisations dÃ©taillÃ©es et des mÃ©triques prÃ©cises pour faciliter la comparaison des performances entre ces deux SGBD.

### ğŸŒŸ Points forts

- Analyse comparative approfondie
- Installation automatisÃ©e via Docker
- Visualisations graphiques dÃ©taillÃ©es
- Tests sur diffÃ©rents types de requÃªtes
- Documentation complÃ¨te

## ğŸ‘¥ Auteurs

- **GrÃ©goire BODIN** - Master 1 IL
- **LÃ©o BERNARD-BORDIER** - Master 1 IL

## ğŸ¯ Objectifs du Projet

Ce projet vise Ã  :

- Comparer les performances de PostgreSQL et MonetDB
- Analyser l'impact des diffÃ©rentes stratÃ©gies d'indexation
- Ã‰valuer les performances sur diffÃ©rents types de requÃªtes :
  - RequÃªtes de sÃ©lection simple
  - Jointures complexes
  - AgrÃ©gations
- Fournir des visualisations claires et dÃ©taillÃ©es des rÃ©sultats

## ğŸ” Rapport

Vous pouvez consulter le rapport complet [ici](raport/main.pdf).

## ğŸš€ Installation

### PrÃ©requis systÃ¨me

- Git
- Docker et Docker Compose
- 4 Go de RAM minimum
- 2 Go d'espace disque disponible

### Installation du projet

1. **Cloner le repository**

   ```bash
   git clone git@github.com:GregoireBDN/Database-Analyzer.git
   cd Database-Analyzer
   ```

2. **Configurer l'environnement**
   ```bash
   cp .env.example .env
   # Modifier les variables dans .env si nÃ©cessaire
   ```

### Installation des donnÃ©es

En raison de leur taille, les fichiers de donnÃ©es doivent Ãªtre tÃ©lÃ©chargÃ©s sÃ©parÃ©ment :

#### Sources des donnÃ©es

- **Air Quality Data** : [NYC Open Data - Air Quality](https://catalog.data.gov/dataset/air-quality)

  - Description : DonnÃ©es de surveillance de la qualitÃ© de l'air Ã  New York
  - Format : CSV
  - Placer dans : `data/air_quality.csv`

- **Crime Data** : [LA City - Crime Data 2020 to Present](https://catalog.data.gov/dataset/crime-data-from-2020-to-present)
  - Description : DonnÃ©es sur la criminalitÃ© Ã  Los Angeles depuis 2020
  - Format : CSV
  - Placer dans : `data/crimes.csv`

#### PrÃ©paration des donnÃ©es

1. CrÃ©er le dossier `data` :
   ```bash
   mkdir -p data
   ```
2. TÃ©lÃ©charger et placer les fichiers CSV dans `data/`
3. VÃ©rifier les noms des fichiers :
   - `data/air_quality.csv`
   - `data/crimes.csv`

### Lancement de l'analyse

Une fois les donnÃ©es installÃ©es :

```bash
chmod +x run.sh
./run.sh
```

## ğŸ“ Structure du projet

```
Database-Analyzer/
â”œâ”€â”€ docker/                 # Configurations Docker
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ monetdb/
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ scripts/
â”‚           â””â”€â”€ start-monetdb.sh
â”œâ”€â”€ scripts/               # Scripts utilitaires
â”‚   â””â”€â”€ init.sh           # Script principal
â”œâ”€â”€ src/                  # Code source Python
â”‚   â”œâ”€â”€ database/        # Connecteurs, loaders et analyseurs
â”‚   â”œâ”€â”€ queries/         # RequÃªtes SQL
â”‚   â”œâ”€â”€ visualization/   # GÃ©nÃ©ration des graphiques
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py         # Point d'entrÃ©e
â”œâ”€â”€ data/                # DonnÃ©es d'analyse
â”‚   â”œâ”€â”€ air_quality.csv
â”‚   â””â”€â”€ crime.csv
â”œâ”€â”€ results/            # Graphiques gÃ©nÃ©rÃ©s
â”œâ”€â”€ raport/             # Rapport de projet en LaTeX
â”‚   â”œâ”€â”€ main.tex        # Fichier principal du rapport
â”‚   â””â”€â”€ main.pdf        # Rapport compilÃ©
â”œâ”€â”€ run.sh              # Script de lancement
â”œâ”€â”€ setup.py           # Configuration du package
â”œâ”€â”€ docker-compose.yml # Configuration des services
â”œâ”€â”€ .env.example       # Template des variables d'environnement
â””â”€â”€ README.md         # Documentation
```

## ğŸ” FonctionnalitÃ©s

- **Configuration automatique**

  - Installation des SGBD
  - CrÃ©ation des bases de donnÃ©es
  - Configuration des utilisateurs et permissions

- **Analyse des performances**

  - Temps d'exÃ©cution des requÃªtes
  - Utilisation des ressources
  - Lecture/Ã©criture disque
  - Impact des index

- **Visualisation**
  - Graphiques comparatifs
  - Statistiques dÃ©taillÃ©es
  - Export des rÃ©sultats

## ğŸ“Š RÃ©sultats

Les rÃ©sultats de l'analyse sont gÃ©nÃ©rÃ©s dans le dossier `results/` et incluent :

- Graphiques de comparaison des temps d'exÃ©cution
- Rapports dÃ©taillÃ©s par type de requÃªte

## ğŸ›  AperÃ§u des RÃ©sultats

### Analyse de la QualitÃ© de l'Air

![Analyse QualitÃ© Air](results/air_quality_performance.png)

Les rÃ©sultats montrent que :

- PostgreSQL est plus efficace pour le chargement initial (0.03 ms/ligne vs 0.22 ms/ligne pour MonetDB)
- Les requÃªtes de sÃ©lection (Q1) et d'agrÃ©gation (Q2) sont similaires en performance
- MonetDB montre des performances infÃ©rieures sur les jointures complexes (Q3) avec un temps d'exÃ©cution ~7x plus Ã©levÃ©

### Analyse des Crimes

![Analyse Crimes](results/crimes_performance.png)

Points clÃ©s :

- MonetDB montre un temps de chargement plus Ã©levÃ© (0.37 ms/ligne vs 0.05 ms/ligne pour PostgreSQL)
- PostgreSQL prÃ©sente des temps d'exÃ©cution significativement plus Ã©levÃ©s pour :
  - Les sÃ©lections (Q1) : ~100ms vs ~15ms pour MonetDB
  - Les agrÃ©gations (Q2) : ~400ms vs ~15ms pour MonetDB
  - Les jointures (Q3) : ~325ms vs ~20ms pour MonetDB
- MonetDB maintient des performances constantes sur tous les types de requÃªtes

### Conclusions

1. **Chargement des donnÃ©es** :

   - PostgreSQL est plus efficace pour le chargement initial des donnÃ©es
   - MonetDB montre des temps de chargement 7-8x plus Ã©levÃ©s

2. **ExÃ©cution des requÃªtes** :

   - PostgreSQL performe mieux sur des requÃªtes de jointure sur un faible volume de donnÃ©es

   - MonetDB excelle sur l'ensemble des requÃªtes avec des volumes de donnÃ©es plus importants

## ğŸ“ Explication des diffÃ©rences de performance

### 1. Chargement des donnÃ©es

PostgreSQL est plus rapide au chargement initial car :

- Il utilise une architecture orientÃ©e ligne (row-oriented)
- Les donnÃ©es sont directement Ã©crites dans le format de stockage final
- OptimisÃ© pour les insertions ligne par ligne

MonetDB est plus lent au chargement car :

- Il utilise une architecture orientÃ©e colonne (column-oriented)
- Les donnÃ©es doivent Ãªtre rÃ©organisÃ©es par colonne lors du chargement
- NÃ©cessite plus d'opÃ©rations de transformation des donnÃ©es

### 2. ExÃ©cution des requÃªtes

#### Sur petit volume de donnÃ©es

PostgreSQL performe mieux car :

**Architecture row-oriented optimisÃ©e**

- Les donnÃ©es d'une mÃªme ligne sont stockÃ©es de maniÃ¨re contiguÃ«
- AccÃ¨s rapide Ã  toutes les colonnes d'une ligne en une seule lecture disque
- IdÃ©al pour les requÃªtes OLTP qui accÃ¨dent Ã  plusieurs colonnes d'une mÃªme ligne

**Gestion efficace des index**

- Index B-tree optimisÃ©s pour les petits volumes
- Maintenance des index moins coÃ»teuse
- Statistiques prÃ©cises pour l'optimiseur de requÃªtes
- Mise Ã  jour rapide des index lors des modifications

**Utilisation optimale du cache**

- Les donnÃ©es frÃ©quemment accÃ©dÃ©es restent en cache
- Buffer pool bien dimensionnÃ© pour petits volumes
- PrÃ©diction de lecture efficace
- Moins de dÃ©fauts de cache (cache misses)

#### Sur grand volume de donnÃ©es

MonetDB devient plus performant grÃ¢ce Ã  :

**Architecture column-oriented optimisÃ©e**

- Stockage par colonne permettant :
  - Lecture sÃ©lective des colonnes nÃ©cessaires
  - RÃ©duction drastique des I/O disque
  - Meilleure utilisation de la bande passante

**Compression avancÃ©e des donnÃ©es**

- Compression par colonne plus efficace
- Algorithmes spÃ©cialisÃ©s par type de donnÃ©es
- DÃ©compression Ã  la volÃ©e optimisÃ©e
- RÃ©duction significative de l'empreinte mÃ©moire

**Optimisations OLAP**

- MatÃ©rialisation tardive des rÃ©sultats
- ParallÃ©lisation automatique des requÃªtes
- Optimisations spÃ©cifiques aux agrÃ©gations
- Gestion efficace des jointures sur grandes tables

**Vectorisation et parallÃ©lisation**

- Instructions CPU vectorielles (SIMD)
- Traitement parallÃ¨le des colonnes
- Pipeline d'exÃ©cution optimisÃ©
- Utilisation maximale des cÅ“urs CPU

### 3. Impact du type d'architecture

#### PostgreSQL (Row-oriented)

âœ… **Avantages**

- Transactions OLTP performantes
  - Verrouillage fin au niveau ligne
  - ACID strict
  - Commit/Rollback rapides
- Efficace sur petits volumes
  - Cache hit ratio Ã©levÃ©
  - Peu de fragmentation
  - Index compacts
- Mise Ã  jour rapide
  - Une seule Ã©criture par modification
  - Journalisation optimisÃ©e
  - Moins de fragmentation

âŒ **InconvÃ©nients**

- Lecture de donnÃ©es inutiles
  - Charge I/O plus importante
  - Gaspillage de bande passante
  - Cache polluÃ© par donnÃ©es non utilisÃ©es
- Performances limitÃ©es sur gros volumes
  - ScalabilitÃ© verticale principalement
  - Compression moins efficace
  - Plus de mouvements de donnÃ©es

#### MonetDB (Column-oriented)

âœ… **Avantages**

- Analyses OLAP optimisÃ©es
  - AgrÃ©gations rapides
  - Jointures efficaces sur grandes tables
  - ParallÃ©lisation naturelle
- Compression efficace
  - Ratio de compression Ã©levÃ©
  - Moins d'I/O disque
  - Meilleure utilisation mÃ©moire
- Ã‰volutivitÃ©
  - ScalabilitÃ© horizontale native
  - ParallÃ©lisation automatique
  - Vectorisation CPU

âŒ **InconvÃ©nients**

- Chargement initial lent
  - RÃ©organisation des donnÃ©es
  - Construction des index
  - Compression des colonnes
- Transactions complexes
  - Verrouillage plus grossier
  - Overhead de reconstruction
  - Latence plus Ã©levÃ©e

## ğŸ“ Licence

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans un cadre universitaire Ã  l'UniversitÃ© de Rennes.
