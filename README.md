# ğŸ“Š Database Analyzer

## ğŸ“‹ Table des matiÃ¨res

1. [Introduction](#-introduction)
2. [Auteurs](#-auteurs)
3. [Objectifs](#-objectifs-du-projet)
4. [PrÃ©requis et DonnÃ©es](#-prÃ©requis-et-donnÃ©es)
   - [PrÃ©requis systÃ¨me](#prÃ©requis-systÃ¨me)
   - [DonnÃ©es requises](#donnÃ©es-requises)
5. [Installation](#-installation)
   - [Installation rapide](#-installation-rapide)
   - [Installation dÃ©taillÃ©e](#-installation-dÃ©taillÃ©e)
6. [Structure du projet](#-structure-du-projet)
7. [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
   - [Configuration automatique](#configuration-automatique)
   - [Analyse des performances](#analyse-des-performances)
   - [Visualisation](#visualisation)
8. [RÃ©sultats](#-rÃ©sultats)
9. [Licence](#-licence)

## ğŸ“ Introduction

Ce projet d'analyse comparative de bases de donnÃ©es a Ã©tÃ© dÃ©veloppÃ© dans le cadre de l'UE "Bases de DonnÃ©es" du Master IngÃ©nierie Logicielle Ã  l'UniversitÃ© de Rennes. Il permet d'Ã©valuer et de comparer les performances de PostgreSQL et MonetDB sur diffÃ©rents types de requÃªtes et scÃ©narios d'utilisation.

L'outil propose une suite complÃ¨te de tests automatisÃ©s, gÃ©nÃ©rant des visualisations dÃ©taillÃ©es et des mÃ©triques prÃ©cises pour faciliter la comparaison des performances entre ces deux SGBD.

### ğŸŒŸ Points forts

- Analyse comparative approfondie
- Installation automatisÃ©e via Docker
- Visualisations graphiques dÃ©taillÃ©es
- Tests sur diffÃ©rents types de requÃªtes
- Documentation complÃ¨te

## ğŸ‘¥ Auteurs

- **GrÃ©goire BODIN** - Master 1 IL
- **LÃ©o BERNARD-BORDIER** - Master 1 IL

## ğŸ¯ Objectifs du Projet

Ce projet vise Ã  :

- Comparer les performances de PostgreSQL et MonetDB
- Analyser l'impact des diffÃ©rentes stratÃ©gies d'indexation
- Ã‰valuer les performances sur diffÃ©rents types de requÃªtes :
  - RequÃªtes de sÃ©lection simple
  - Jointures complexes
  - AgrÃ©gations
- Fournir des visualisations claires et dÃ©taillÃ©es des rÃ©sultats

## ğŸ“‹ PrÃ©requis et DonnÃ©es

### PrÃ©requis systÃ¨me

- Git
- Docker et Docker Compose
- 4 Go de RAM minimum
- 2 Go d'espace disque disponible

Le script d'installation s'occupera automatiquement de :

- La crÃ©ation des conteneurs Docker
- L'installation des SGBD
- La configuration de l'environnement
- L'importation des donnÃ©es de test

### DonnÃ©es requises

En raison de leur taille, les fichiers de donnÃ©es ne sont pas inclus directement dans le dÃ©pÃ´t. Vous devez les tÃ©lÃ©charger sÃ©parÃ©ment :

#### Sources des donnÃ©es

- **Air Quality Data** : [NYC Open Data - Air Quality](https://catalog.data.gov/dataset/air-quality)

  - Description : DonnÃ©es de surveillance de la qualitÃ© de l'air Ã  New York
  - Format : CSV

- **Crime Data** : [LA City - Crime Data 2020 to Present](https://catalog.data.gov/dataset/crime-data-from-2020-to-present)
  - Description : DonnÃ©es sur la criminalitÃ© Ã  Los Angeles depuis 2020
  - Format : CSV

## ğŸš€ Installation

### Installation rapide

1. **Cloner le repository**

   ```bash
   git clone git@github.com:GregoireBDN/Database-Analyzer.git
   cd Database-Analyzer
   ```

2. **Configurer l'environnement**

   ```bash
   cp .env.example .env
   # Modifier les variables dans .env si nÃ©cessaire
   ```

3. **Lancer l'installation et l'analyse**

   ```bash
   chmod +x run.sh
   ./run.sh
   ```

4. **Installation des donnÃ©es**

5. CrÃ©er le dossier `data` s'il n'existe pas :

```bash
mkdir -p data
```

2. TÃ©lÃ©charger les fichiers CSV et les placer dans le dossier `data/`

3. VÃ©rifier que les fichiers sont correctement nommÃ©s :

- `data/air_quality.csv`
- `data/crimes.csv`

Note : Ces fichiers sont nÃ©cessaires pour exÃ©cuter les analyses. Le dossier `data/` est ignorÃ© par Git en raison de la taille des fichiers.

### Installation dÃ©taillÃ©e

1. **Configuration de l'environnement**

   - Copier `.env.example` vers `.env`
   - Ajuster les paramÃ¨tres selon vos besoins :
     - Ports des bases de donnÃ©es
     - Identifiants de connexion
     - Taille des lots de donnÃ©es

2. **PrÃ©paration des donnÃ©es**

   1. CrÃ©er le dossier `data` s'il n'existe pas :

   ```bash
   mkdir -p data
   ```

3. TÃ©lÃ©charger les fichiers CSV et les placer dans le dossier `data/`

4. VÃ©rifier que les fichiers sont correctement nommÃ©s :

- `data/air_quality.csv`
- `data/crimes.csv`

Note : Ces fichiers sont nÃ©cessaires pour exÃ©cuter les analyses. Le dossier `data/` est ignorÃ© par Git en raison de la taille des fichiers.

3. **Lancement des services**

   ```bash
   docker compose up -d
   ```

4. **VÃ©rification de l'installation**
   ```bash
   docker compose ps
   ```

## ğŸ“ Structure du projet

```
Database-Analyzer/
â”œâ”€â”€ docker/                 # Configurations Docker
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ monetdb/
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ scripts/
â”‚           â””â”€â”€ start-monetdb.sh
â”œâ”€â”€ scripts/               # Scripts utilitaires
â”‚   â””â”€â”€ init.sh           # Script principal
â”œâ”€â”€ src/                  # Code source Python
â”‚   â”œâ”€â”€ database/        # Connecteurs, loaders et analyseurs
â”‚   â”œâ”€â”€ queries/         # RequÃªtes SQL
â”‚   â”œâ”€â”€ visualization/   # GÃ©nÃ©ration des graphiques
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py         # Point d'entrÃ©e
â”œâ”€â”€ data/                # DonnÃ©es d'analyse
â”‚   â”œâ”€â”€ air_quality.csv
â”‚   â””â”€â”€ crime.csv
â”œâ”€â”€ results/            # Graphiques gÃ©nÃ©rÃ©s
â”œâ”€â”€ run.sh              # Script de lancement
â”œâ”€â”€ setup.py           # Configuration du package
â”œâ”€â”€ docker-compose.yml # Configuration des services
â”œâ”€â”€ .env.example       # Template des variables d'environnement
â””â”€â”€ README.md         # Documentation
```

## ğŸ” FonctionnalitÃ©s

- **Configuration automatique**

  - Installation des SGBD
  - CrÃ©ation des bases de donnÃ©es
  - Configuration des utilisateurs et permissions

- **Analyse des performances**

  - Temps d'exÃ©cution des requÃªtes
  - Utilisation des ressources
  - Lecture/Ã©criture disque
  - Impact des index

- **Visualisation**
  - Graphiques comparatifs
  - Statistiques dÃ©taillÃ©es
  - Export des rÃ©sultats

## ğŸ“Š RÃ©sultats

Les rÃ©sultats de l'analyse sont gÃ©nÃ©rÃ©s dans le dossier `results/` et incluent :

- Graphiques de comparaison des temps d'exÃ©cution
- Rapports dÃ©taillÃ©s par type de requÃªte

## ğŸ›  AperÃ§u des RÃ©sultats

### Analyse de la QualitÃ© de l'Air

![Analyse QualitÃ© Air](results/air_quality_performance.png)

Les rÃ©sultats montrent que :

- PostgreSQL est plus efficace pour le chargement initial (0.03 ms/ligne vs 0.22 ms/ligne pour MonetDB)
- Les requÃªtes de sÃ©lection (Q1) et d'agrÃ©gation (Q2) sont similaires en performance
- MonetDB montre des performances infÃ©rieures sur les jointures complexes (Q3) avec un temps d'exÃ©cution ~7x plus Ã©levÃ©

### Analyse des Crimes

![Analyse Crimes](results/crimes_performance.png)

Points clÃ©s :

- MonetDB montre un temps de chargement plus Ã©levÃ© (0.37 ms/ligne vs 0.05 ms/ligne pour PostgreSQL)
- PostgreSQL prÃ©sente des temps d'exÃ©cution significativement plus Ã©levÃ©s pour :
  - Les agrÃ©gations (Q2) : ~400ms vs ~15ms pour MonetDB
  - Les jointures (Q3) : ~325ms vs ~20ms pour MonetDB
- MonetDB maintient des performances constantes sur tous les types de requÃªtes

### Conclusions

1. **Chargement des donnÃ©es** :

   - PostgreSQL est plus efficace pour le chargement initial des donnÃ©es
   - MonetDB montre des temps de chargement 7-8x plus Ã©levÃ©s

2. **ExÃ©cution des requÃªtes** :
   - MonetDB excelle dans les opÃ©rations d'agrÃ©gation et de jointure sur grands volumes
   - PostgreSQL performe mieux sur les requÃªtes de sÃ©lection simples
   - Les diffÃ©rences de performance sont plus marquÃ©es sur le jeu de donnÃ©es "Crimes" (plus volumineux)

## ğŸ“ Licence

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans un cadre universitaire Ã  l'UniversitÃ© de Rennes.
